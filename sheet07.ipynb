{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Log-sum-exp and soft(arg)max\n",
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x, lamb=1):\n",
    "    # TODO: implement the logsumexp\n",
    "\n",
    "# TODO: set up a grid of points in [-1, 1] x [-1, 1]\n",
    "\n",
    "\n",
    "# TODO: I recommend you set up a function to set up an Axes object with the correct x, y labels, \n",
    "#       equal aspect and maybe x and y ticks.\n",
    "\n",
    "def set_up_axes(ax):\n",
    "    \n",
    "# TODO: calculate and plot the functions as specified in the task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis, lamb=1):\n",
    "    # TODO: implement the softmax function. Axis should specify along which axis the sums should be computed.\n",
    "\n",
    "        \n",
    "# TODO: compute the argmax of each gridpoint in one-hot form\n",
    "onehot_argmax = to_onehot(np.argmax(xy, axis=-1))\n",
    "\n",
    "# TODO: make the plots as specified on the sheet (nicest is in a grid which you can get using plt.subplots)\n",
    "\n",
    "# plot the softmax\n",
    "fig, axs = plt.subplots(2, 4, figsize=(17, 7))\n",
    "        \n",
    "# plot the onehot argmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Abs(nn.Module):\n",
    "    \"\"\"Absolute value activation function. You can experiment with this instead of ReLU.\"\"\"\n",
    "    def forward(self, x):\n",
    "        return x.abs()\n",
    "    \n",
    "    \n",
    "# define NN architecture.\n",
    "class MLPShallow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: initialize Linear Layers and the activation as specified on the sheet\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: pass the input x through the layers and return the output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, res=500, bound=5):\n",
    "    # TODO: implement a function that takes the model (the MLP), and builds a \n",
    "    #       grid of points in [-bound, bound] x [-bound, bound], passes them \n",
    "    #       through the model and returns the result in the shape of an image\n",
    "\n",
    "\n",
    "# TODO: instantiate the model and make the visualizations as requested in the task\n",
    "# NOTE: If you get a constant output, you got an unlucky initialization. Simply reinitialize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the spatial gradient of the network outputs (as an image) from (b)\n",
    "#       using np.gradient, and visualize using matplotlib's prism colormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN architecture.\n",
    "class MLPDeep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: initialize Linear Layers and the activation as specified on the sheet\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: pass the input x through the layers and return the output\n",
    "\n",
    "# TODO: repeat the visualizations from above\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
